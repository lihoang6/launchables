{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ Turn Your Notebook into a Launchable\n",
        "## *From Demo to GPU-Backed Distribution*\n",
        "\n",
        "Welcome! If you've built a notebook showcasing your AI work - whether it's a library, model, technique, or tutorial - this guide shows you how to transform it into a **Launchable**: instantly accessible to developers worldwide with GPU backing.\n",
        "\n",
        "---\n",
        "\n",
        "## Why Launchables?\n",
        "\n",
        "**The Problem**: You've built something amazing. But developers:\n",
        "- ‚ùå Struggle with setup and dependencies\n",
        "- ‚ùå Don't have GPUs to run your demos\n",
        "- ‚ùå Give up before seeing your innovation\n",
        "- ‚ùå Can't easily share with their teams\n",
        "\n",
        "**The Solution**: Launchables on Brev\n",
        "- ‚úÖ One click ‚Üí Instant GPU environment\n",
        "- ‚úÖ Pre-configured and working\n",
        "- ‚úÖ Shareable link ‚Üí Anyone can try it\n",
        "- ‚úÖ Higher adoption and engagement\n",
        "\n",
        "---\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "By the end of this tutorial:\n",
        "\n",
        "‚úÖ **Learn** the essential components of Launchables and transform your current work (in this example, we're going to configure Unsloth to enable access to 181+ notebooks) \n",
        "‚úÖ **Package Your Existing Notebook** - Transform your current work (in this example, we're going to configure Unsloth to enable access to 181+ notebooks) \n",
        "‚úÖ **Deploy to Brev** - One-click hosting with GPU Acceleration \n",
        "‚úÖ **Share with the World** - Give developers and team members instant access  \n",
        "\n",
        "> **üí° Key Insight**: A Launchable is just a well-structured notebook + requirements.txt + GPU verification. You probably already have 80% of what you need!\n",
        "\n",
        "---\n",
        "\n",
        "**The Impact**:\n",
        "\n",
        "| Metric | Before Launchables | After Launchables | Impact |\n",
        "|--------|-------------------|-------------------|--------|\n",
        "| Setup Time | 2+ hours | 30 seconds | **240x faster** |\n",
        "| Success Rate | ~30% | ~95% | **3x more** adoption |\n",
        "| User Friction | High | None | Lower churn |\n",
        "| Viral Sharing | Difficult | One link | Easier growth |\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Tutorial Roadmap\n",
        "\n",
        "### Part 1: Foundations (~15 min)\n",
        "1. **Launchables Structure** - File organization and patterns\n",
        "2. **System, Dependencies, and GPU Verification** - The critical first step\n",
        "3. **Why This Matters** - Real impact on adoption\n",
        "\n",
        "### Part 2: Transformation (~45 min)\n",
        "4. **GPU-First Development** - Ensuring acceleration works\n",
        "5. **Building Demos** - Interactive, engaging examples\n",
        "6. **Packaging** - Dependencies and documentation\n",
        "\n",
        "### Part 3: Distribution (~20 min)\n",
        "7. **Git & GitHub** - Version control workflow\n",
        "8. **Deploying to Brev** - Making it accessible\n",
        "9. **Best Practices** - Lessons from successful Launchables\n",
        "\n",
        "### Part 4: Your Turn (~20 min)\n",
        "10. **Hands-On Exercise** - Convert a real example\n",
        "11. **Resources & Next Steps** - Join the ecosystem\n",
        "\n",
        "**Total: ~30 minutes from existing notebook to deployed Launchable**\n",
        "\n",
        "---\n",
        "\n",
        "## Real Example: A Developer using Unsloth",
        "\n",
        "**Before**: Unsloth had a notebook showing 2x faster fine-tuning. Users had to:\n",
        "- Clone repo, install dependencies, get a GPU, debug issues ‚Üí 2+ hours\n",
        "- Success rate: ~30% of users\n",
        "\n",
        "**After**: Developer created a Launchable. Users:\n",
        "- Click link ‚Üí Working environment in 30 seconds\n",
        "- Success rate: ~95% of users\n",
        "- **Result**: 3x more developers trying and adopting Unsloth\n",
        "\n",
        "---\n",
        "\n",
        "**Ready to make your innovation accessible?** Let's verify your System, Dependencies, and GPU and get started! üëá\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 1: Foundations\n",
        "\n",
        "## Section 1: What is a Launchable? üéØ\n",
        "\n",
        "### The Core Concept\n",
        "\n",
        "A **Launchable** transforms your existing notebook into a distribution-ready format:\n",
        "\n",
        "**Your Notebook** + **GPU Verification** + **Dependencies** + **Documentation** = **Launchable**\n",
        "\n",
        "It's that simple! If you already have a notebook demonstrating your AI library, model, or technique, you're 80% done.\n",
        "\n",
        "---\n",
        "\n",
        "### The Three Essential Components\n",
        "\n",
        "Every successful Launchable has:\n",
        "\n",
        "1. **üî• System, Dependencies, and GPU Verification** (CRITICAL!)\n",
        "   - First executable cell\n",
        "   - Checks GPU availability via nvidia-smi\n",
        "   - Checks `requirements.txt` with all packages\n",
        "   - Shows system hardware details\n",
        "\n",
        "---\n",
        "\n",
        "### The Launchables Ecosystem\n",
        "\n",
        "- **Platform**: [Brev.dev](https://brev.dev) - NVIDIA's GPU cloud for instant deployment\n",
        "- **Repository**: [github.com/brevdev/launchables](https://github.com/brevdev/launchables) - Community examples\n",
        "- **Your Role**: Create content ‚Üí Developers discover and use ‚Üí Ecosystem grows\n",
        "\n",
        "---\n",
        "\n",
        "## üî• STEP 1: GPU Verification (CRITICAL!)\n",
        "\n",
        "**This is the FIRST cell in any Launchable.**\n",
        "\n",
        "Why? Because if users don't have a working GPU:\n",
        "- Models run 10-100x slower (or fail)\n",
        "- They blame your library, not the setup\n",
        "- Bad first impression = lost users\n",
        "\n",
        "Let's verify GPU now ‚¨áÔ∏è\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "üî• CRITICAL GPU VERIFICATION\n",
        "This cell MUST be the first executable cell in every launchable!\n",
        "\"\"\"\n",
        "\n",
        "# Auto-install torch if not available\n",
        "import sys\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è  torch not found - installing now (this takes 2-3 minutes)...\")\n",
        "    try:\n",
        "        # Try with pip module first\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torch\"], \n",
        "                            stderr=subprocess.DEVNULL)\n",
        "    except:\n",
        "        # Fallback to direct pip command\n",
        "        try:\n",
        "            subprocess.check_call([\"pip\", \"install\", \"-q\", \"torch\"],\n",
        "                                stderr=subprocess.DEVNULL)\n",
        "        except:\n",
        "            # Last resort - try pip3\n",
        "            subprocess.check_call([\"pip3\", \"install\", \"-q\", \"torch\"],\n",
        "                                stderr=subprocess.DEVNULL)\n",
        "    print(\"‚úÖ torch installed! Continuing...\")\n",
        "    import torch\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üîç GPU VERIFICATION REPORT\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Check Python version\n",
        "print(f\"\\nüìå Python Version: {sys.version.split()[0]}\")\n",
        "\n",
        "# Check PyTorch version\n",
        "print(f\"üìå PyTorch Version: {torch.__version__}\")\n",
        "\n",
        "# Check CUDA availability\n",
        "cuda_available = torch.cuda.is_available()\n",
        "print(f\"\\n{'‚úÖ' if cuda_available else '‚ùå'} CUDA Available: {cuda_available}\")\n",
        "\n",
        "if cuda_available:\n",
        "    # GPU Details\n",
        "    gpu_count = torch.cuda.device_count()\n",
        "    print(f\"‚úÖ Number of GPUs: {gpu_count}\")\n",
        "    \n",
        "    for i in range(gpu_count):\n",
        "        print(f\"\\nüìä GPU {i} Details:\")\n",
        "        print(f\"   Name: {torch.cuda.get_device_name(i)}\")\n",
        "        print(f\"   Compute Capability: {torch.cuda.get_device_capability(i)}\")\n",
        "        \n",
        "        # Memory info\n",
        "        total_memory = torch.cuda.get_device_properties(i).total_memory / 1e9\n",
        "        print(f\"   Total Memory: {total_memory:.2f} GB\")\n",
        "        \n",
        "        # Current memory usage\n",
        "        allocated = torch.cuda.memory_allocated(i) / 1e9\n",
        "        reserved = torch.cuda.memory_reserved(i) / 1e9\n",
        "        print(f\"   Allocated Memory: {allocated:.2f} GB\")\n",
        "        print(f\"   Reserved Memory: {reserved:.2f} GB\")\n",
        "    \n",
        "    # Test GPU with a simple operation\n",
        "    print(\"\\nüß™ Testing GPU with sample tensor operation...\")\n",
        "    test_tensor = torch.randn(1000, 1000).cuda()\n",
        "    result = torch.matmul(test_tensor, test_tensor)\n",
        "    print(f\"‚úÖ GPU test successful! Result shape: {result.shape}\")\n",
        "    print(f\"‚úÖ Tensor is on device: {result.device}\")\n",
        "    \n",
        "    # Clean up\n",
        "    del test_tensor, result\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"üéâ SUCCESS! Your GPU is ready for AI development!\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "else:\n",
        "    # Fallback message\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"‚ö†Ô∏è  WARNING: No GPU detected!\")\n",
        "    print(\"=\" * 70)\n",
        "    print(\"\\nüîß Troubleshooting Steps:\")\n",
        "    print(\"1. Verify nvidia-smi works: Run 'nvidia-smi' in terminal\")\n",
        "    print(\"2. Check CUDA installation: Visit https://developer.nvidia.com/cuda-downloads\")\n",
        "    print(\"3. Reinstall PyTorch with CUDA: https://pytorch.org/get-started/locally/\")\n",
        "    print(\"4. Verify GPU drivers are up to date\")\n",
        "    print(\"\\nüí° Common Issues:\")\n",
        "    print(\"   - Wrong PyTorch version (CPU-only)\")\n",
        "    print(\"   - CUDA version mismatch\")\n",
        "    print(\"   - GPU drivers not installed\")\n",
        "    print(\"\\n‚ö†Ô∏è  This launchable requires a GPU to run properly.\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "# Set default device for rest of notebook\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"\\nüéØ Default device set to: {device}\")\n",
        "print(f\"‚úÖ All future operations will use: {device.type.upper()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment Setup Checklist\n",
        "\n",
        "Before we continue, make sure you have:\n",
        "\n",
        "**Required:**\n",
        "- ‚úÖ GPU detected (verified above)\n",
        "- ‚úÖ PyTorch with CUDA support installed\n",
        "- ‚úÖ Jupyter notebook running\n",
        "- ‚úÖ Git installed (`git --version` in terminal)\n",
        "- ‚úÖ GitHub account created\n",
        "\n",
        "**Recommended:**\n",
        "- üìù Code editor (VSCode, Cursor, or similar)\n",
        "- üêô Git configured with SSH keys\n",
        "- üåê Brev.dev account (for deployment later)\n",
        "\n",
        "### Quick Environment Check\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Quick environment check - verify all key dependencies\n",
        "\"\"\"\n",
        "\n",
        "import subprocess\n",
        "import importlib\n",
        "\n",
        "def check_import(package_name, display_name=None):\n",
        "    \"\"\"Check if a package can be imported and get its version\"\"\"\n",
        "    if display_name is None:\n",
        "        display_name = package_name\n",
        "    try:\n",
        "        module = importlib.import_module(package_name)\n",
        "        version = getattr(module, '__version__', 'unknown')\n",
        "        print(f\"‚úÖ {display_name}: {version}\")\n",
        "        return True\n",
        "    except ImportError:\n",
        "        print(f\"‚ùå {display_name}: Not installed\")\n",
        "        return False\n",
        "\n",
        "def check_command(command, name):\n",
        "    \"\"\"Check if a command is available\"\"\"\n",
        "    try:\n",
        "        result = subprocess.run([command, '--version'], \n",
        "                              capture_output=True, text=True, timeout=5)\n",
        "        version_line = result.stdout.split('\\n')[0] if result.stdout else result.stderr.split('\\n')[0]\n",
        "        print(f\"‚úÖ {name}: {version_line}\")\n",
        "        return True\n",
        "    except (subprocess.TimeoutExpired, FileNotFoundError):\n",
        "        print(f\"‚ùå {name}: Not found\")\n",
        "        return False\n",
        "\n",
        "print(\"üîç Checking Dependencies...\\n\")\n",
        "\n",
        "# Python packages\n",
        "check_import('torch', 'PyTorch')\n",
        "check_import('transformers', 'Transformers')\n",
        "check_import('numpy', 'NumPy')\n",
        "check_import('matplotlib', 'Matplotlib')\n",
        "\n",
        "print()\n",
        "\n",
        "# System tools\n",
        "check_command('git', 'Git')\n",
        "check_command('nvidia-smi', 'nvidia-smi')\n",
        "\n",
        "print(\"\\n‚úÖ Environment check complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 2: Understanding the Launchables Structure üìÅ\n",
        "\n",
        "## The Launchables Pattern\n",
        "\n",
        "A well-structured launchable follows this pattern:\n",
        "\n",
        "```\n",
        "your-launchable/\n",
        "‚îú‚îÄ‚îÄ README.md                 # Overview, prerequisites, quick start\n",
        "‚îú‚îÄ‚îÄ requirements.txt          # Python dependencies with versions\n",
        "‚îú‚îÄ‚îÄ .gitignore               # Exclude cache, models, etc.\n",
        "‚îú‚îÄ‚îÄ main-notebook.ipynb      # Your interactive tutorial\n",
        "‚îî‚îÄ‚îÄ (optional) assets/       # Images, data files, etc.\n",
        "```\n",
        "\n",
        "### Why This Structure?\n",
        "\n",
        "1. **README.md** - First thing people see. Must be compelling!\n",
        "2. **requirements.txt** - Reproducible environment setup\n",
        "3. **.gitignore** - Keep repo clean (no model checkpoints!)\n",
        "4. **Notebook** - Self-contained learning experience\n",
        "5. **Assets** - Supporting materials (keep them small!)\n",
        "\n",
        "## Examples from the Ecosystem\n",
        "\n",
        "Let's look at real launchables:\n",
        "\n",
        "### Example 1: Model Fine-tuning\n",
        "```\n",
        "fine-tune-llama/\n",
        "‚îú‚îÄ‚îÄ README.md              # \"Fine-tune Llama 2 in 30 minutes\"\n",
        "‚îú‚îÄ‚îÄ requirements.txt       # torch, transformers, datasets, peft\n",
        "‚îú‚îÄ‚îÄ fine-tune.ipynb       # Step-by-step tutorial\n",
        "‚îî‚îÄ‚îÄ sample-data/          # Small example dataset\n",
        "```\n",
        "\n",
        "### Example 2: Production Deployment\n",
        "```\n",
        "vllm-production/\n",
        "‚îú‚îÄ‚îÄ README.md              # \"Deploy LLMs at scale\"\n",
        "‚îú‚îÄ‚îÄ requirements.txt       # vllm, fastapi, uvicorn\n",
        "‚îú‚îÄ‚îÄ deployment.ipynb      # Interactive setup guide\n",
        "‚îî‚îÄ‚îÄ config/               # Sample configurations\n",
        "```\n",
        "\n",
        "### Example 3: This Tutorial!\n",
        "```\n",
        "how-to-build-launchables/\n",
        "‚îú‚îÄ‚îÄ README.md              # What you're learning\n",
        "‚îú‚îÄ‚îÄ requirements.txt       # All dependencies\n",
        "‚îú‚îÄ‚îÄ .gitignore            # Clean repo\n",
        "‚îî‚îÄ‚îÄ how-to-build-launchables.ipynb  # This file!\n",
        "```\n",
        "\n",
        "## Best Practices\n",
        "\n",
        "### ‚úÖ DO:\n",
        "- Keep notebooks focused (1-2 hours to complete)\n",
        "- Include working code examples\n",
        "- Test on fresh environment before sharing\n",
        "- Add clear error messages\n",
        "- Use GPU verification at start\n",
        "- Include progress indicators\n",
        "\n",
        "### ‚ùå DON'T:\n",
        "- Commit large model files (use `.gitignore`)\n",
        "- Hardcode personal paths or tokens\n",
        "- Skip GPU verification\n",
        "- Make assumptions about environment\n",
        "- Leave broken cells\n",
        "- Forget to test end-to-end\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Exercise: Understanding Structure\n",
        "\n",
        "Look at this repository's structure. Can you identify:\n",
        "1. Where are the dependencies listed?\n",
        "2. What files are ignored by git?\n",
        "3. How is this notebook organized?\n",
        "\n",
        "**Answer**: Use `!ls -la` to explore!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explore the repository structure\n",
        "import os\n",
        "\n",
        "print(\"üìÅ Current Directory Structure:\\n\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# List files in current directory\n",
        "files = os.listdir('.')\n",
        "files.sort()\n",
        "\n",
        "for file in files:\n",
        "    if file.startswith('.'):\n",
        "        icon = \"üîí\"  # Hidden file\n",
        "    elif file.endswith('.ipynb'):\n",
        "        icon = \"üìì\"\n",
        "    elif file.endswith('.md'):\n",
        "        icon = \"üìù\"\n",
        "    elif file.endswith('.txt'):\n",
        "        icon = \"üìÑ\"\n",
        "    elif file.endswith('.py'):\n",
        "        icon = \"üêç\"\n",
        "    elif os.path.isdir(file):\n",
        "        icon = \"üìÇ\"\n",
        "    else:\n",
        "        icon = \"üìÑ\"\n",
        "    \n",
        "    size = \"DIR\" if os.path.isdir(file) else f\"{os.path.getsize(file):,} bytes\"\n",
        "    print(f\"{icon} {file:<40} {size}\")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nüí° Notice:\")\n",
        "print(\"   - requirements.txt defines our dependencies\")\n",
        "print(\"   - .gitignore keeps repo clean\")\n",
        "print(\"   - This notebook is self-contained\")\n",
        "print(\"   - README.md provides overview\")\n"
      ]
    },
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
