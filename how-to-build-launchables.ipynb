{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\ude80 How to Build Brev Launchables\n",
        "\n",
        "Welcome! This tutorial teaches you how to transform your AI notebooks into **shareable, GPU-backed experiences** that anyone can run with one click.\n",
        "\n",
        "## What You'll Build Today\n",
        "\n",
        "- \u2705 GPU-verified interactive demos\n",
        "- \u2705 Shareable prototypes for your ecosystem  \n",
        "- \u2705 Working examples that help others be 10x faster with local GPU\n",
        "- \u2705 Live showcases of your tooling and techniques\n",
        "\n",
        "## Who This Is For\n",
        "\n",
        "**AI creators in the ecosystem** who want to:\n",
        "- Share their tooling and techniques\n",
        "- Make their work discoverable\n",
        "- Help others prototype faster\n",
        "\n",
        "## Tutorial Structure\n",
        "\n",
        "1. **Why Build Launchables?** - Value proposition and use cases\n",
        "2. **Your First Simple Demo** - Load and run a model on GPU\n",
        "3. **Making It Interactive** - Add engagement and user controls\n",
        "4. **Best Practices** - Patterns for great launchables\n",
        "5. **Sharing Your Launchable** - GitHub and Brev deployment\n",
        "6. **Your Challenge** - Build your own!\n",
        "\n",
        "**Estimated time:** 45-60 minutes\n",
        "\n",
        "---\n",
        "\n",
        "Let's get started! \ud83d\udc47\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Install Required Packages\n",
        "# This installs everything needed for this tutorial in your notebook's kernel\n",
        "\n",
        "import sys\n",
        "!{sys.executable} -m pip install -q torch transformers accelerate matplotlib numpy tqdm ipywidgets\n",
        "\n",
        "print(\"=\"  * 60)\n",
        "print(\"\u2705 Installation complete!\")\n",
        "print(\"=\"  * 60)\n",
        "print(\"\\n\u26a0\ufe0f  IMPORTANT: Please restart the kernel now\")\n",
        "print(\"   - Click 'Kernel' \u2192 'Restart' in the menu\")\n",
        "print(\"   - Then run all cells below\")\n",
        "print(\"=\"  * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## \u26a0\ufe0f Restart Kernel Required\n",
        "\n",
        "**After running the installation cell above:**\n",
        "1. Click `Kernel` \u2192 `Restart` in the menu\n",
        "2. Run all cells below from this point forward\n",
        "\n",
        "This ensures the newly installed packages are loaded correctly.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: GPU Verification\n",
        "# This verifies your GPU is available and ready to use\n",
        "\n",
        "import torch\n",
        "\n",
        "print(\"\ud83d\udd0d GPU Verification Report\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"\u2705 CUDA Available: Yes\")\n",
        "    print(f\"\u2705 GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"\u2705 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(f\"\u2705 CUDA Version: {torch.version.cuda}\")\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"\\n\ud83c\udf89 GPU is ready!\")\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f WARNING: No GPU detected\")\n",
        "    print(\"This tutorial requires a GPU-enabled instance.\")\n",
        "    print(\"Please deploy this launchable on a GPU-enabled environment.\")\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"\\n\ud83c\udfaf Using device: {device}\")\n",
        "print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 1: Why Build Launchables? \ud83c\udfaf\n",
        "\n",
        "## The Problem\n",
        "\n",
        "You've built something amazing - a new technique, an optimized model, a useful tool. But when you share it:\n",
        "\n",
        "- \u274c Users struggle with dependencies and setup\n",
        "- \u274c They don't have GPUs to run your demos\n",
        "- \u274c Many give up before seeing your innovation work\n",
        "- \u274c Your impact is limited by friction\n",
        "\n",
        "## The Solution: Launchables\n",
        "\n",
        "A **Launchable** is a self-contained, GPU-backed notebook that:\n",
        "\n",
        "- \u2705 Runs with one click\n",
        "- \u2705 Includes automatic GPU access\n",
        "- \u2705 Has all dependencies pre-specified\n",
        "- \u2705 Works immediately - no setup required\n",
        "\n",
        "## Use Cases\n",
        "\n",
        "**Great launchables showcase:**\n",
        "- \"10x faster fine-tuning\" techniques\n",
        "- Novel model architectures anyone can try\n",
        "- Optimization tools and benchmarks\n",
        "- Interactive tutorials and demos\n",
        "- Research paper reproductions\n",
        "\n",
        "## Real Impact\n",
        "\n",
        "When your notebook becomes a launchable:\n",
        "- **Setup time:** 2 hours \u2192 30 seconds (240x faster)\n",
        "- **Success rate:** 30% \u2192 95% (3x more users succeed)\n",
        "- **Adoption:** 3-5x more developers try your work\n",
        "- **Discoverability:** Featured in launchables ecosystem\n",
        "\n",
        "**In this section, you'll:** Learn what makes a great launchable and see a simple example.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 2: Your First Simple Demo \ud83d\ude80\n",
        "\n",
        "Let's build a minimal working example. You'll:\n",
        "- Load a tiny model (DistilGPT2)\n",
        "- Place it explicitly on GPU\n",
        "- Run simple inference\n",
        "- Show GPU memory usage\n",
        "\n",
        "**This is the foundation of every launchable.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and run a simple model on GPU\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "import time\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"\ud83d\ude80 Simple GPU Demo: Text Generation\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Load model\n",
        "print(\"\\n\ud83d\udce5 Loading DistilGPT2...\")\n",
        "model_name = \"distilgpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# Move to GPU explicitly\n",
        "print(f\"\ud83d\udd04 Moving model to {device}...\")\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Verify placement\n",
        "model_device = next(model.parameters()).device\n",
        "print(f\"\u2705 Model is on: {model_device}\")\n",
        "\n",
        "# Show GPU memory\n",
        "if torch.cuda.is_available():\n",
        "    memory_used = torch.cuda.memory_allocated(0) / 1e9\n",
        "    print(f\"\ud83d\udcbe GPU Memory Used: {memory_used:.2f} GB\")\n",
        "\n",
        "# Generate text\n",
        "print(\"\\n\ud83c\udfa8 Generating text...\")\n",
        "prompt = \"Brev launchables make AI development\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "start = time.time()\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_length=40,\n",
        "        do_sample=True,\n",
        "        temperature=0.8,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "generation_time = time.time() - start\n",
        "\n",
        "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(f\"\\n\ud83d\udcdd Result: {generated_text}\")\n",
        "print(f\"\u26a1 Time: {generation_time:.2f}s\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"\u2705 Demo complete! Your GPU is working.\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \u2705 What You Just Learned\n",
        "\n",
        "You successfully:\n",
        "1. Loaded a model\n",
        "2. Moved it to GPU explicitly (`.to(device)`)\n",
        "3. Verified GPU placement\n",
        "4. Monitored GPU memory\n",
        "5. Ran inference on GPU\n",
        "\n",
        "**This pattern applies to ANY model you want to showcase!**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 3: Making It Interactive \ud83c\udfa8\n",
        "\n",
        "Great launchables aren't just code - they're **engaging experiences**. Let's add:\n",
        "- User-editable parameters\n",
        "- Visual feedback\n",
        "- Timing metrics\n",
        "- Clear outputs\n",
        "\n",
        "**In this section, you'll:** Build an interactive sentiment analyzer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive sentiment analysis demo\n",
        "\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "import time\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"\ud83c\udfad Interactive Sentiment Analysis\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Load pipeline on GPU\n",
        "device_id = 0 if torch.cuda.is_available() else -1\n",
        "classifier = pipeline(\"sentiment-analysis\", device=device_id)\n",
        "\n",
        "print(f\"\\n\u2705 Model loaded on: {'GPU' if device_id == 0 else 'CPU'}\")\n",
        "\n",
        "# User-editable test cases\n",
        "test_texts = [\n",
        "    \"Launchables make sharing AI work so easy!\",\n",
        "    \"Setup took forever and nothing worked.\",\n",
        "    \"The tutorial is clear and examples run perfectly.\",\n",
        "]\n",
        "\n",
        "print(\"\\n\ud83d\udca1 Try editing test_texts above and rerunning this cell!\\n\")\n",
        "\n",
        "# Analyze each text\n",
        "for i, text in enumerate(test_texts, 1):\n",
        "    print(f\"Text {i}: \\\"{text}\\\"\")\n",
        "    \n",
        "    start = time.time()\n",
        "    result = classifier(text)[0]\n",
        "    inference_time = time.time() - start\n",
        "    \n",
        "    # Visual output\n",
        "    sentiment = result['label']\n",
        "    confidence = result['score'] * 100\n",
        "    emoji = \"\ud83d\ude0a\" if sentiment == \"POSITIVE\" else \"\ud83d\ude1e\"\n",
        "    \n",
        "    print(f\"  {emoji} {sentiment} ({confidence:.1f}% confident)\")\n",
        "    print(f\"  \u26a1 {inference_time*1000:.0f}ms\\n\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"\u2705 Interactive demo complete!\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \u2705 What You Just Learned\n",
        "\n",
        "You built an interactive demo with:\n",
        "1. **User-editable parameters** - Edit `test_texts` and rerun\n",
        "2. **Visual feedback** - Emojis and formatted output\n",
        "3. **Timing metrics** - Shows inference speed\n",
        "4. **Clear results** - Easy to understand\n",
        "\n",
        "**This pattern makes your launchables engaging and shareable!**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 4: Best Practices \u2b50\n",
        "\n",
        "## Essential Patterns for Great Launchables\n",
        "\n",
        "### \u2705 Always Include\n",
        "\n",
        "- [ ] **GPU verification first** - Users need to know if GPU is available\n",
        "- [ ] **Explicit device placement** - Always use `.to(device)`\n",
        "- [ ] **Clear outputs** - Show what's happening at each step\n",
        "- [ ] **Timing metrics** - Prove GPU acceleration works\n",
        "- [ ] **User invitation** - \"Try changing X to see Y\"\n",
        "\n",
        "### \u2705 Structure Your Launchable\n",
        "\n",
        "1. **Title and intro** - What will users learn?\n",
        "2. **Installation** - One cell with all dependencies\n",
        "3. **GPU verification** - Verify hardware\n",
        "4. **Simple demo first** - Show it works immediately\n",
        "5. **Interactive demo** - Let users experiment\n",
        "6. **Next steps** - How to build their own\n",
        "\n",
        "### \u2705 File Requirements\n",
        "\n",
        "Your launchable repository needs:\n",
        "```\n",
        "your-launchable/\n",
        "\u251c\u2500\u2500 README.md              # Short overview (< 200 words)\n",
        "\u251c\u2500\u2500 requirements.txt       # All pip dependencies\n",
        "\u251c\u2500\u2500 your-notebook.ipynb   # Self-contained tutorial\n",
        "\u2514\u2500\u2500 .gitignore            # Standard Python/Jupyter\n",
        "```\n",
        "\n",
        "### \u2705 Common Mistakes to Avoid\n",
        "\n",
        "- \u274c **Don't** assume packages are installed\n",
        "- \u274c **Don't** use terminal instructions (Brev opens notebook directly)\n",
        "- \u274c **Don't** make it too complex (keep under 20 cells)\n",
        "- \u274c **Don't** forget to test on fresh kernel\n",
        "- \u274c **Don't** use \"production\" language (call it \"shareable prototype\")\n",
        "\n",
        "### \u2705 Language Guidelines\n",
        "\n",
        "**Instead of:**\n",
        "- \"Production-ready deployment\" \u2192 \"Shareable prototype\"\n",
        "- \"Enterprise-grade\" \u2192 \"Working demo\"\n",
        "- \"Build AI systems\" \u2192 \"Share your AI work\"\n",
        "\n",
        "**Target audience:**\n",
        "- \"AI creators in the ecosystem\"\n",
        "- \"Help others be 10x faster with local GPU\"\n",
        "- \"Make your tooling discoverable\"\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 5: Sharing Your Launchable \ud83d\udce4\n",
        "\n",
        "Ready to share your launchable with the world? Here's how.\n",
        "\n",
        "## Step 1: Prepare Your Repository\n",
        "\n",
        "**Create these files:**\n",
        "\n",
        "### `requirements.txt`\n",
        "```txt\n",
        "torch>=2.0.0\n",
        "transformers>=4.30.0\n",
        "accelerate>=0.20.0\n",
        "```\n",
        "\n",
        "### `README.md`\n",
        "```markdown\n",
        "# Your Launchable Title\n",
        "\n",
        "One-sentence description of what this showcases.\n",
        "\n",
        "## What You'll Build\n",
        "- Bullet point 1\n",
        "- Bullet point 2\n",
        "\n",
        "## Prerequisites\n",
        "- GPU-enabled environment\n",
        "- Python 3.8+\n",
        "\n",
        "## Get Started\n",
        "Click \"Open Notebook\" to start.\n",
        "```\n",
        "\n",
        "### `.gitignore`\n",
        "```gitignore\n",
        "# Python\n",
        "__pycache__/\n",
        "*.pyc\n",
        "\n",
        "# Jupyter\n",
        ".ipynb_checkpoints/\n",
        "\n",
        "# Models\n",
        "*.pt\n",
        "*.pth\n",
        "*.bin\n",
        "```\n",
        "\n",
        "## Step 2: Push to GitHub\n",
        "\n",
        "```bash\n",
        "git init\n",
        "git add .\n",
        "git commit -m \"Create launchable for [your project]\"\n",
        "git remote add origin https://github.com/yourusername/your-launchable.git\n",
        "git push -u origin main\n",
        "```\n",
        "\n",
        "## Step 3: Deploy on Brev\n",
        "\n",
        "1. **Go to** [console.brev.dev](https://console.brev.dev)\n",
        "2. **Connect** your GitHub repository\n",
        "3. **Select** GPU tier (T4 recommended for most demos)\n",
        "4. **Launch** and test your launchable\n",
        "5. **Share** the launch link with your community!\n",
        "\n",
        "## Resources\n",
        "\n",
        "- **Brev Documentation**: [docs.nvidia.com/brev/latest/launchables.html](https://docs.nvidia.com/brev/latest/launchables.html)\n",
        "- **Launchables Ecosystem**: [github.com/brevdev/launchables](https://github.com/brevdev/launchables)\n",
        "- **Examples**: Browse existing launchables for inspiration\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 6: Your Challenge \ud83c\udfaf\n",
        "\n",
        "## Build Your Own Launchable!\n",
        "\n",
        "You now have everything you need. Here's your challenge:\n",
        "\n",
        "### Option 1: Transform an Existing Notebook\n",
        "\n",
        "Take a notebook you already have and:\n",
        "- [ ] Add GPU verification as first cell\n",
        "- [ ] Add installation cell with all dependencies\n",
        "- [ ] Make device placement explicit\n",
        "- [ ] Add timing metrics\n",
        "- [ ] Create short README (< 200 words)\n",
        "- [ ] Test on fresh kernel\n",
        "- [ ] Push to GitHub\n",
        "- [ ] Deploy on Brev\n",
        "\n",
        "### Option 2: Build Something New\n",
        "\n",
        "**Ideas for your first launchable:**\n",
        "- \"10x faster [technique]\" demo\n",
        "- Novel model architecture showcase\n",
        "- Optimization comparison tool\n",
        "- Interactive tutorial for your library\n",
        "- Paper reproduction with working code\n",
        "\n",
        "### Getting Started\n",
        "\n",
        "1. **Pick your topic** - What do you want to share?\n",
        "2. **Create the notebook** - Start with GPU verification\n",
        "3. **Keep it simple** - 10-15 cells maximum\n",
        "4. **Test it works** - Run all cells on fresh kernel\n",
        "5. **Share it** - Push to GitHub, deploy on Brev\n",
        "\n",
        "### Join the Ecosystem\n",
        "\n",
        "When your launchable is ready:\n",
        "- Share on social media with #BrevLaunchables\n",
        "- Add to the [launchables showcase](https://github.com/brevdev/launchables)\n",
        "- Help other creators with their launchables\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83c\udf89 Congratulations!\n",
        "\n",
        "You've completed the tutorial. You now know how to:\n",
        "- \u2705 Verify GPU availability\n",
        "- \u2705 Build interactive demos\n",
        "- \u2705 Follow best practices\n",
        "- \u2705 Share your work as a launchable\n",
        "\n",
        "**Now go make your AI work discoverable and help others be 10x faster!** \ud83d\ude80\n",
        "\n",
        "---\n",
        "\n",
        "*Tutorial created for AI creators in the Brev ecosystem*  \n",
        "*Making AI work shareable, one launchable at a time* \ud83d\udc9a\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}