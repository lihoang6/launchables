{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NVIDIA Nemotron Nano 9B v2 - Interactive Demo\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook provides an interactive demonstration of **NVIDIA Nemotron Nano 9B v2** capabilities using NVIDIA NIM. Experience the power of this compact 9B parameter model through hands-on examples.\n",
        "\n",
        "## What You'll Explore\n",
        "\n",
        "- ðŸ’¬ **Conversational AI**: Natural language understanding and generation\n",
        "- ðŸ”§ **Function Calling**: Intelligent tool use and parameter extraction\n",
        "- ðŸŽ­ **Roleplay**: Consistent persona-based interactions\n",
        "- ðŸ§© **Reasoning**: Step-by-step problem solving\n",
        "\n",
        "## Model Information\n",
        "\n",
        "**Nemotron Nano 9B v2** specifications:\n",
        "- **Parameters**: 9 Billion (optimized architecture)\n",
        "- **Context Length**: 8K tokens\n",
        "- **Inference Speed**: <100ms (optimized deployment)\n",
        "- **License**: MIT (commercial use allowed)\n",
        "- **Strengths**: Function calling, reasoning, code generation\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- NVIDIA API key from [build.nvidia.com](https://build.nvidia.com/)\n",
        "- Python 3.8+\n",
        "- Internet connection\n",
        "\n",
        "Let's get started! ðŸš€\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Install required packages and configure API access.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "def install_package(package_name):\n",
        "    \"\"\"Install a package handling various environment scenarios\"\"\"\n",
        "    try:\n",
        "        # Try using pip module\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n",
        "        print(f\"âœ… Successfully installed {package_name} using pip\")\n",
        "    except subprocess.CalledProcessError:\n",
        "        try:\n",
        "            # Try ensurepip to bootstrap pip first\n",
        "            print(\"âš ï¸ pip not found, attempting to install pip...\")\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"ensurepip\", \"--default-pip\"])\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\"])\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n",
        "            print(f\"âœ… Successfully installed pip and {package_name}\")\n",
        "        except:\n",
        "            try:\n",
        "                # Try conda as fallback\n",
        "                subprocess.check_call([\"conda\", \"install\", \"-y\", package_name])\n",
        "                print(f\"âœ… Successfully installed {package_name} using conda\")\n",
        "            except:\n",
        "                print(f\"âŒ Failed to install {package_name}\")\n",
        "                print(f\"Please run manually: {sys.executable} -m pip install {package_name}\")\n",
        "                print(f\"Or: pip install {package_name}\")\n",
        "                raise\n",
        "\n",
        "# Install openai\n",
        "install_package(\"openai\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "print(\"âœ… Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## API Configuration\n",
        "\n",
        "Set your NVIDIA API key. Get one at [build.nvidia.com](https://build.nvidia.com/)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure API key\n",
        "NVIDIA_API_KEY = \"YOUR_API_KEY_HERE\"  # Replace with your key\n",
        "# Or use: NVIDIA_API_KEY = os.getenv(\"NVIDIA_API_KEY\")\n",
        "\n",
        "# Validate API key\n",
        "if NVIDIA_API_KEY == \"YOUR_API_KEY_HERE\" or not NVIDIA_API_KEY:\n",
        "    raise ValueError(\n",
        "        \"âŒ ERROR: Please set your NVIDIA API key!\\n\\n\"\n",
        "        \"Steps:\\n\"\n",
        "        \"1. Go to https://build.nvidia.com/\\n\"\n",
        "        \"2. Sign in and generate an API key\\n\"\n",
        "        \"3. Replace 'YOUR_API_KEY_HERE' above with your actual key\\n\"\n",
        "        \"4. Re-run this cell\\n\\n\"\n",
        "        \"Example: NVIDIA_API_KEY = 'nvapi-xxxxxxxxxxxxx'\"\n",
        "    )\n",
        "\n",
        "# Initialize client\n",
        "client = OpenAI(\n",
        "    base_url=\"https://integrate.api.nvidia.com/v1\",\n",
        "    api_key=NVIDIA_API_KEY\n",
        ")\n",
        "\n",
        "print(\"âœ… NVIDIA NIM client initialized!\")\n",
        "print(f\"ðŸ”‘ API key: {NVIDIA_API_KEY[:10]}...{NVIDIA_API_KEY[-4:]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test API Connection\n",
        "\n",
        "Let's verify your API key works and check available models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test API connection and list available models\n",
        "try:\n",
        "    models = client.models.list()\n",
        "    print(\"âœ… API connection successful!\\n\")\n",
        "    print(\"Available models:\")\n",
        "    for model in models.data:\n",
        "        if \"nemotron\" in model.id.lower() or \"llama\" in model.id.lower():\n",
        "            print(f\"  - {model.id}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ API Error: {e}\")\n",
        "    print(\"\\nTroubleshooting:\")\n",
        "    print(\"1. Go to https://build.nvidia.com/\")\n",
        "    print(\"2. Find 'Nemotron Nano' in the catalog\")\n",
        "    print(\"3. Click 'Get API Key' and accept terms\")\n",
        "    print(\"4. Make sure your API key has access to the model\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Demo 1: Conversational AI ðŸ’¬\n",
        "\n",
        "Let's start with a simple conversation showcasing the model's natural language understanding.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def chat(prompt, system_prompt=\"You are a helpful AI assistant.\", stream=True):\n",
        "    \"\"\"Simple chat function with streaming support\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"nvidia/nemotron-nano-9b-v2\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.7,\n",
        "        max_tokens=1024,\n",
        "        stream=stream\n",
        "    )\n",
        "    \n",
        "    if stream:\n",
        "        print(\"ðŸ¤– Nemotron: \", end=\"\", flush=True)\n",
        "        full_response = \"\"\n",
        "        for chunk in response:\n",
        "            if chunk.choices[0].delta.content:\n",
        "                content = chunk.choices[0].delta.content\n",
        "                print(content, end=\"\", flush=True)\n",
        "                full_response += content\n",
        "        print(\"\\n\")\n",
        "        return full_response\n",
        "    else:\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "# Test it out!\n",
        "print(\"ðŸ‘¤ You: Explain quantum computing in simple terms\\n\")\n",
        "chat(\"Explain quantum computing in simple terms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Try Code Generation\n",
        "\n",
        "The model excels at generating clean, functional code.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"ðŸ‘¤ You: Write a Python function to calculate Fibonacci numbers\\n\")\n",
        "chat(\"Write a Python function to calculate Fibonacci numbers with proper documentation\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Demo 2: Function Calling ðŸ”§\n",
        "\n",
        "Nemotron Nano 9B v2 can intelligently decide which functions to call based on user requests.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Define available functions\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_weather\",\n",
        "            \"description\": \"Get current weather for a location\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\"type\": \"string\", \"description\": \"City name\"},\n",
        "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]}\n",
        "                },\n",
        "                \"required\": [\"location\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"calculate\",\n",
        "            \"description\": \"Perform mathematical calculations\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"expression\": {\"type\": \"string\", \"description\": \"Math expression to evaluate\"}\n",
        "                },\n",
        "                \"required\": [\"expression\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "def demo_function_calling(user_query):\n",
        "    \"\"\"Demonstrate function calling\"\"\"\n",
        "    print(f\"ðŸ‘¤ You: {user_query}\\n\")\n",
        "    \n",
        "    response = client.chat.completions.create(\n",
        "        model=\"nvidia/nemotron-nano-9b-v2\",\n",
        "        messages=[{\"role\": \"user\", \"content\": user_query}],\n",
        "        tools=tools,\n",
        "        tool_choice=\"auto\"\n",
        "    )\n",
        "    \n",
        "    message = response.choices[0].message\n",
        "    \n",
        "    if message.tool_calls:\n",
        "        print(\"ðŸ”§ Model Decision: Call a function\\n\")\n",
        "        tool_call = message.tool_calls[0]\n",
        "        print(f\"ðŸ“ž Function: {tool_call.function.name}\")\n",
        "        print(f\"ðŸ“ Arguments: {tool_call.function.arguments}\\n\")\n",
        "        \n",
        "        # Pretty print the parsed arguments\n",
        "        args = json.loads(tool_call.function.arguments)\n",
        "        print(\"âœ¨ Extracted Parameters:\")\n",
        "        for key, value in args.items():\n",
        "            print(f\"   â€¢ {key}: {value}\")\n",
        "    else:\n",
        "        print(f\"ðŸ¤– Response: {message.content}\")\n",
        "    print()\n",
        "\n",
        "# Test different queries\n",
        "demo_function_calling(\"What's the weather in Tokyo?\")\n",
        "demo_function_calling(\"Calculate 15% tip on $89.50\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Demo 3: Roleplay Scenarios ðŸŽ­\n",
        "\n",
        "The model can maintain consistent personas throughout conversations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def roleplay_demo(persona, user_message):\n",
        "    \"\"\"Demonstrate roleplay with different personas\"\"\"\n",
        "    personas = {\n",
        "        \"tutor\": \"You are a patient, encouraging AI tutor who explains concepts clearly with examples.\",\n",
        "        \"coder\": \"You are an expert programming assistant who writes clean, efficient code with best practices.\",\n",
        "        \"writer\": \"You are a creative writer who crafts engaging narratives with vivid descriptions.\"\n",
        "    }\n",
        "    \n",
        "    print(f\"ðŸŽ­ Persona: {persona.title()}\")\n",
        "    print(f\"ðŸ‘¤ You: {user_message}\\n\")\n",
        "    \n",
        "    chat(user_message, system_prompt=personas[persona])\n",
        "\n",
        "# Try different personas\n",
        "roleplay_demo(\"tutor\", \"I don't understand recursion. Can you help?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "roleplay_demo(\"coder\", \"Write a function to reverse a linked list\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Demo 4: Reasoning Challenges ðŸ§©\n",
        "\n",
        "Watch the model solve complex problems with step-by-step reasoning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reasoning_prompts = {\n",
        "    \"logic\": \"Three people are in a room. Alex is taller than Blake but shorter than Casey. Who is the tallest? Think step-by-step.\",\n",
        "    \"math\": \"If you have a 3-gallon jug and a 5-gallon jug, how can you measure exactly 4 gallons? Explain your reasoning.\",\n",
        "    \"lateral\": \"A man lives on the 15th floor. Every day he takes the elevator down. On the way back, he takes it to the 7th floor and walks the rest. Why? Provide logical reasoning.\"\n",
        "}\n",
        "\n",
        "def solve_puzzle(puzzle_type):\n",
        "    \"\"\"Demonstrate reasoning capabilities\"\"\"\n",
        "    prompt = reasoning_prompts[puzzle_type]\n",
        "    print(f\"ðŸ§© Puzzle Type: {puzzle_type.title()}\")\n",
        "    print(f\"â“ Question: {prompt}\\n\")\n",
        "    \n",
        "    response = chat(prompt, system_prompt=\"You are a logical reasoning expert. Think step-by-step and show your work.\", stream=False)\n",
        "    print(f\"ðŸ¤– Solution:\\n{response}\\n\")\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Solve different types of puzzles\n",
        "solve_puzzle(\"logic\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "solve_puzzle(\"math\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Multi-Turn Conversation\n",
        "\n",
        "Build context over multiple exchanges.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conversation = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"}\n",
        "]\n",
        "\n",
        "def continue_conversation(user_input):\n",
        "    \"\"\"Continue a multi-turn conversation\"\"\"\n",
        "    conversation.append({\"role\": \"user\", \"content\": user_input})\n",
        "    print(f\"ðŸ‘¤ You: {user_input}\\n\")\n",
        "    \n",
        "    response = client.chat.completions.create(\n",
        "        model=\"nvidia/nemotron-nano-9b-v2\",\n",
        "        messages=conversation,\n",
        "        temperature=0.7,\n",
        "        max_tokens=512\n",
        "    )\n",
        "    \n",
        "    assistant_msg = response.choices[0].message.content\n",
        "    conversation.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
        "    \n",
        "    print(f\"ðŸ¤– Nemotron: {assistant_msg}\\n\")\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Have a conversation\n",
        "continue_conversation(\"What are the benefits of edge AI deployment?\")\n",
        "continue_conversation(\"Can you give me specific examples in manufacturing?\")\n",
        "continue_conversation(\"What hardware would I need?\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Summary\n",
        "\n",
        "You've explored the key capabilities of **NVIDIA Nemotron Nano 9B v2**:\n",
        "\n",
        "âœ… **Conversational AI** - Natural, context-aware dialogue  \n",
        "âœ… **Function Calling** - Intelligent tool use and parameter extraction  \n",
        "âœ… **Roleplay** - Consistent persona-based interactions  \n",
        "âœ… **Reasoning** - Step-by-step problem solving  \n",
        "âœ… **Multi-turn Context** - Maintaining conversation history\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "- ðŸ“˜ Check out `Integrate_With_NIM.ipynb` for more advanced patterns\n",
        "- ðŸš€ Deploy with NVIDIA NIM for production use\n",
        "- ðŸ”§ Customize functions and personas for your use case\n",
        "- ðŸ“š Read the [NVIDIA NIM Documentation](https://docs.nvidia.com/nim/)\n",
        "\n",
        "## Resources\n",
        "\n",
        "- [NVIDIA NIM](https://www.nvidia.com/en-us/ai/)\n",
        "- [Nemotron Model Family](https://developer.nvidia.com/nemotron)\n",
        "- [API Catalog](https://build.nvidia.com/)\n",
        "- [Documentation](https://docs.nvidia.com/nim/)\n",
        "\n",
        "---\n",
        "\n",
        "**Built with â¤ï¸ for the NVIDIA AI community**\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
